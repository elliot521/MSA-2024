{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3c1cb34",
   "metadata": {},
   "source": [
    "# MSA 2024 Phase 2 - Part 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48d550cf",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc85f3a2",
   "metadata": {},
   "source": [
    "### 1. Data loading & preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3985907",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "train_dir = 'train'\n",
    "test_dir = 'test'\n",
    "\n",
    "def loadTrain(root_dir, csv_file):\n",
    "    ids = []\n",
    "    images = []\n",
    "    labels = []\n",
    "    annotations = pd.read_csv(csv_file)\n",
    "    for idx, row in annotations.iterrows():\n",
    "        img_id = int(row['id'])\n",
    "        img_name = os.path.join(root_dir, f\"image_{img_id}.png\")\n",
    "        image = np.array(Image.open(img_name).convert(\"RGB\"))\n",
    "        label = int(row['label'])\n",
    "\n",
    "        ids.append(img_id)\n",
    "        images.append(image)\n",
    "        labels.append(label)\n",
    "    return np.array(ids), np.array(images), np.array(labels)\n",
    "\n",
    "# Load test data\n",
    "def loadTest(root_dir):\n",
    "    ids = []\n",
    "    images = []\n",
    "    for img_name in os.listdir(root_dir):\n",
    "        img_id = int(img_name.split('_')[1].split('.')[0])\n",
    "        img_path = os.path.join(root_dir, img_name)\n",
    "        image = np.array(Image.open(img_path).convert(\"RGB\"))\n",
    "\n",
    "        ids.append(img_id)\n",
    "        images.append(image)\n",
    "    return np.array(ids), np.array(images)\n",
    "\n",
    "# Load training, testing data and the training labels provided in train.csv\n",
    "train_csv = '/Users/elliotbu/Desktop/MSA 2024/3. Deep Learning/train.csv'\n",
    "id_train, X_train, y_train = loadTrain(train_dir, train_csv)\n",
    "id_test, X_test = loadTest(test_dir)\n",
    "\n",
    "# Normalize the data and reshape\n",
    "X_train = X_train.astype('float32') / 255.0\n",
    "X_test = X_test.astype('float32') / 255.0\n",
    "X_train = X_train.reshape(-1, 32*32*3)  \n",
    "X_test = X_test.reshape(-1, 32*32*3)    \n",
    "\n",
    "# Convert training labels to one-hot encoded vectors\n",
    "y_train = to_categorical(y_train, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261ae9e8",
   "metadata": {},
   "source": [
    "### 2. Build & train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92d60add",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/elliotbu/Library/Python/3.9/lib/python/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.0980 - loss: 2.4114 - val_accuracy: 0.1014 - val_loss: 2.3026\n",
      "Epoch 2/20\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1024 - loss: 2.3026 - val_accuracy: 0.0977 - val_loss: 2.3026\n",
      "Epoch 3/20\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0984 - loss: 2.3028 - val_accuracy: 0.1022 - val_loss: 2.3027\n",
      "Epoch 4/20\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0991 - loss: 2.3027 - val_accuracy: 0.0980 - val_loss: 2.3028\n",
      "Epoch 5/20\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1021 - loss: 2.3027 - val_accuracy: 0.0952 - val_loss: 2.3027\n",
      "Epoch 6/20\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0980 - loss: 2.3028 - val_accuracy: 0.0980 - val_loss: 2.3027\n",
      "Epoch 7/20\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.0987 - loss: 2.3027 - val_accuracy: 0.0997 - val_loss: 2.3028\n",
      "Epoch 8/20\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0955 - loss: 2.3028 - val_accuracy: 0.0952 - val_loss: 2.3028\n",
      "Epoch 9/20\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1023 - loss: 2.3027 - val_accuracy: 0.0952 - val_loss: 2.3028\n",
      "Epoch 10/20\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0998 - loss: 2.3027 - val_accuracy: 0.1014 - val_loss: 2.3027\n",
      "Epoch 11/20\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0990 - loss: 2.3027 - val_accuracy: 0.0952 - val_loss: 2.3028\n",
      "Epoch 12/20\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1003 - loss: 2.3027 - val_accuracy: 0.0952 - val_loss: 2.3029\n",
      "Epoch 13/20\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0998 - loss: 2.3027 - val_accuracy: 0.0952 - val_loss: 2.3027\n",
      "Epoch 14/20\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0981 - loss: 2.3027 - val_accuracy: 0.0980 - val_loss: 2.3027\n",
      "Epoch 15/20\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1006 - loss: 2.3027 - val_accuracy: 0.0977 - val_loss: 2.3029\n",
      "Epoch 16/20\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1011 - loss: 2.3027 - val_accuracy: 0.0952 - val_loss: 2.3028\n",
      "Epoch 17/20\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1013 - loss: 2.3026 - val_accuracy: 0.0997 - val_loss: 2.3026\n",
      "Epoch 18/20\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0998 - loss: 2.3027 - val_accuracy: 0.0977 - val_loss: 2.3027\n",
      "Epoch 19/20\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0994 - loss: 2.3027 - val_accuracy: 0.0952 - val_loss: 2.3029\n",
      "Epoch 20/20\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0985 - loss: 2.3027 - val_accuracy: 0.0952 - val_loss: 2.3028\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 586us/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# Build the MLP model with dropout layers\n",
    "model.add(Dense(128, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# Compile the model \n",
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model for more epochs to ensure accuracy\n",
    "model.fit(X_train, y_train, epochs=20, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions = model.predict(X_test)\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "\n",
    "submission = pd.DataFrame({'id': id_test, 'label': predicted_labels})\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd18f1c",
   "metadata": {},
   "source": [
    "## 3. Summary "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43eaf426",
   "metadata": {},
   "source": [
    "Exploratory Data Analysis (EDA):\n",
    "\n",
    "In this notebook, the focus shifts to classification tasks using neural networks. The dataset used is CIFAR-10, a standard dataset for image classification. The EDA involves loading and exploring the CIFAR-10 dataset, understanding its structure, and visualizing sample images to get an idea of the data distribution and class balance. Basic statistics about the dataset, such as the number of classes, image dimensions, and the number of samples, are examined.\n",
    "\n",
    "Preprocessing Steps:\n",
    "\n",
    "Preprocessing for neural network models includes transforming the image data into a suitable format for model training. This involves normalizing the pixel values, converting labels to categorical format using one-hot encoding, and splitting the dataset into training and testing sets. The preprocessing steps ensure that the data is in the correct format for feeding into a neural network model. Additionally, data augmentation techniques may be applied to enhance the model's ability to generalize by artificially expanding the training dataset through transformations like rotation, flipping, and scaling.\n",
    "\n",
    "Model Implementation and Accuracy Evaluation:\n",
    "\n",
    "A simple Multi-Layer Perceptron (MLP) model is built using TensorFlow and Keras. The model is compiled with the Adam optimizer and sparse categorical cross-entropy loss function. Training involves running the model for a fixed number of epochs while monitoring validation accuracy. After training, the model's performance is evaluated on the test set to ensure it generalizes well. The results, including accuracy, are saved to submission.csv for further evaluation. Accuracy is calculated by comparing the predicted labels with the actual labels in the test set, providing a quantitative measure of the model's performance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
